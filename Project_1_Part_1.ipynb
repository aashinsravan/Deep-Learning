{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aashinsravan/Deep-Learning/blob/main/Project_1_Part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln0STPG_CqVl"
      },
      "source": [
        "# Kaggle Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2Q2_haU9oyE",
        "outputId": "1f8d0ee4-cbe2-4cd4-de66-f0eeed903e17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ],
      "source": [
        " ! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXO2f2pxCxCH"
      },
      "source": [
        "# Mounting the Drive and Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CASp-JJR-p32",
        "outputId": "94e58257-80dc-4cab-babf-b6e5d2bdc326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZLycxTf_Xex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf9a7f8-c78b-44e9-90c3-4bdc582c9e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "! mkdir ~/.kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hHWs8Lj_pLi"
      },
      "outputs": [],
      "source": [
        "! cp /content/drive/MyDrive/Colab\\ Notebooks/kaggle_API/kaggle.json ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4yetQ65BgjV"
      },
      "outputs": [],
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APOs5GNNByv1",
        "outputId": "776748f1-991a-4716-fcb5-a1555926464c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wildfire-prediction-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "#Downloading the dataset\n",
        "!kaggle datasets download -d abdelghaniaaba/wildfire-prediction-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGPtlW1fCDQi",
        "outputId": "a2af1928-2878-4932-e622-ae92aeb68984"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  wildfire-prediction-dataset.zip\n",
            "replace /content/test/nowildfire/-113.91777,50.901087.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "#Unzipping the dataset\n",
        "!unzip wildfire-prediction-dataset.zip -d /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQSK60OyFqk0"
      },
      "source": [
        "# Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Zhx8L-ZFpsF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from keras.optimizers import SGD, adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bFWH-AFDQul"
      },
      "source": [
        "# Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Oc9-qGJh4_U"
      },
      "source": [
        "Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DHlIWa2h4e2"
      },
      "outputs": [],
      "source": [
        "EPOCH= 10\n",
        "BATCH_SIZE= 64\n",
        "TRGT_SIZE =(64,64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE3Ftw4oEs3s"
      },
      "source": [
        "Assigning the paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCkKmr2cDWJF"
      },
      "outputs": [],
      "source": [
        "train_path='/content/train'\n",
        "test_path='/content/test'\n",
        "val_path='/content/valid'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AqJsxDDFdiJ"
      },
      "source": [
        "Setting up image data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b_xdnEbFdCy"
      },
      "outputs": [],
      "source": [
        "train_datagen= ImageDataGenerator(rescale=1./255,\n",
        "                                  shear_range=0.2, \n",
        "                                  zoom_range=0.2, \n",
        "                                  horizontal_flip=True,\n",
        "                                  rotation_range=75)\n",
        "\n",
        "test_datagen= ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator=train_datagen.flow_from_directory(train_path, \n",
        "                                                  target_size=TRGT_SIZE, \n",
        "                                                  batch_size=BATCH_SIZE, \n",
        "                                                  class_mode='binary')\n",
        "\n",
        "val_generator = test_datagen.flow_from_directory(val_path,\n",
        "                                                  target_size=TRGT_SIZE,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_path,\n",
        "                                                   target_size=TRGT_SIZE,\n",
        "                                                   batch_size=BATCH_SIZE,\n",
        "                                                   class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt7ttNNDQFbc"
      },
      "source": [
        "# Defining the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8YhdA-4QHRA"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3,3), activation='relu', kernel_initializer='he_uniform', input_shape=(64,64,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',  kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',  kernel_initializer='he_uniform'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFlNKZq3SlA2"
      },
      "source": [
        "# Compiling the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stqAohC9Sm04"
      },
      "outputs": [],
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "model.compile( optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15OJlzb3S7Ya"
      },
      "source": [
        "# Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwG2Gs_puDQz"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = next(train_generator)\n",
        "X_valid, y_valid = next(val_generator)\n",
        "print(f\"Train data shape: {X_train.shape}\")\n",
        "print(f\"Train labels shape: {y_train.shape}\")\n",
        "print(f\"Validation data shape: {X_valid.shape}\")\n",
        "print(f\"Validation labels shape: {y_valid.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5yJM1eXS6G9"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint('model.hdf5',verbose=1, save_best_only= True)\n",
        "early_stopping = EarlyStopping(monitor= 'val_loss', patience= 10)\n",
        "with tf.device('/GPU:0'):\n",
        "  history = model.fit( train_generator,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_data = val_generator,\n",
        "                    validation_steps=len(val_generator),\n",
        "                    callbacks=[checkpoint, early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QobjMv7SFko8"
      },
      "source": [
        "# Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF7KtISoFkZ5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'], label = 'train',)\n",
        "plt.plot(history.history['val_accuracy'], label = 'valid')\n",
        "\n",
        "# adding legend and labels\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "\n",
        "# show the plot\n",
        "plt.show()   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDKjXWnCL9Tg"
      },
      "source": [
        "# Testing the Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgzGrD35R9DE"
      },
      "source": [
        "Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6koeP3U_QMMZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# Load the saved model\n",
        "model.load_weights('model.hdf5')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "scores = model.evaluate(test_generator, steps=len(test_generator), verbose=1)\n",
        "print(f\"Test loss: {scores[0]}\")\n",
        "print(f\"Test accuracy: {scores[1]}\")\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "print(classification_report(test_generator.classes, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MWt5LthR-2J"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfypIBwBSA6V"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Load the saved model\n",
        "model.load_weights('model.hdf5')\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(test_generator.classes, y_pred)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting confusion matrix\n",
        "import seaborn as sns\n",
        "cf_matrix = confusion_matrix(test_generator.classes, y_pred, normalize='true')\n",
        "plt.figure(figsize = (17,12))\n",
        "sns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(test_generator.classes)), yticklabels = sorted(set(test_generator.classes)),cbar=False)\n",
        "plt.title('Normalized Confusion Matrix', fontsize = 23)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.xlabel(\"Predicted\", fontsize=15)\n",
        "plt.ylabel(\"Actual\", fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L9cMyM3fmWm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the saved model\n",
        "model.load_weights('model.hdf5')\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = model.predict(test_generator, steps=len(test_generator), verbose=1)\n",
        "y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(test_generator.classes, y_pred)\n",
        "\n",
        "# Define class labels\n",
        "class_names = ['Non-Fire', 'Fire']\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VHrXurLPypn1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaTNMbsHzqDpM4zpYgmwqX",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}